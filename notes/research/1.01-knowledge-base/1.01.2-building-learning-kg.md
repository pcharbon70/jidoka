# Building learning knowledge graphs for LLM-powered coding assistants

An agentic coding assistant that learns about a project over time requires a sophisticated integration of structured knowledge representation with neural language understanding. **The most promising approach combines code-specific ontologies (like CodeOntology and SEON), LLM-driven knowledge extraction from conversations and code, and hybrid GraphRAG architectures that leverage both symbolic reasoning and neural retrieval.** For an Elixir/BEAM implementation using Jido, the ecosystem provides mature foundations through RDF.ex, Bolt.Sips (Neo4j), and libgraph, enabling a practical path to production.

This synthesis reveals that the field has reached an inflection point: academic work on software engineering ontologies is now merging with practical LLM-augmented knowledge graph construction, creating new possibilities for coding assistants that genuinely learn and remember project context over time.

---

## Existing ontologies provide strong foundations for code representation

Several mature ontologies already model software engineering concepts with varying levels of formalism and practical tooling. **CodeOntology** stands out as the most production-ready option—an OWL 2 ontology with 65 classes, 86 object properties, and a working parser that serializes source code to RDF triples. It models the complete hierarchy from projects and packages down to individual statements and expressions, capturing type systems, method invocations, exception handling, and inheritance relationships.

The **SEON (Software Engineering Ontology Network)** from Brazil takes a more rigorous approach, building on the UFO foundational ontology across three layers: foundational concepts, core software process abstractions, and domain-specific extensions for requirements, design, and testing. Its pattern-based engineering approach offers excellent theoretical grounding but lacks the direct code serialization capabilities of CodeOntology.

For representing code evolution and repository mining, **SE-ON** (University of Zurich) provides a five-layer pyramid architecture spanning general concepts through system-specific extensions for tools like Jira and Bugzilla. Its History Ontology captures revisions, branches, and releases, while its Clone Ontology models code duplication—both valuable for understanding how codebases evolve.

**GraphGen4Code** from IBM Research takes a different approach entirely, using named graphs in RDF to model individual programs while linking library calls to documentation and forum discussions. Applied to 1.3 million Python files with over 2 billion triples, it demonstrates that code knowledge graphs can scale to real-world dimensions.

For Elixir/BEAM specifically, none of these ontologies directly support functional programming constructs, OTP behaviours, supervision trees, or actor-model semantics. A practical implementation would need to extend CodeOntology's structural patterns with custom classes for:

- **Modules and functions** with multiple clauses and pattern matching
- **OTP behaviours** (GenServer, Supervisor, Application) and their callbacks
- **Supervision trees** and process relationships
- **Protocols and implementations** (Elixir's approach to polymorphism)
- **Macros** and compile-time code generation
- **TypeSpecs** from Dialyzer annotations

---

## LLMs can extract and maintain structured knowledge from code and conversations

The integration of LLMs with knowledge graph construction has matured rapidly since 2023. Two paradigms dominate: **schema-based extraction** where predefined ontological structures guide LLM outputs, and **schema-free extraction** where LLMs discover entities and relationships dynamically.

For software engineering contexts, schema-based approaches prove more reliable. The SPIRES framework (Structured Prompt Interrogation and Recursive Extraction of Semantics) performs zero-shot knowledge extraction conforming to user-defined schemas, recursively interrogating the LLM until outputs match the provided structure. Studies show that providing modular ontology guidance in prompts achieves approximately **90% accuracy** in triple extraction—a dramatic improvement over unguided extraction.

The most effective extraction pipeline combines:

1. **Static analysis as ground truth**: AST parsing with Tree-sitter provides reliable structural information about code entities and their relationships
2. **LLM semantic enrichment**: Language models add purpose annotations, parameter explanations, and semantic relationships that static analysis cannot infer
3. **Self-verification loops**: Prompting the LLM to verify whether extracted entities match expected types reduces hallucination
4. **Confidence scoring**: Tracking extraction certainty enables downstream filtering of low-quality triples

For maintaining consistency as code evolves, the **AIR framework** uses importance scoring to identify triples most affected by changes, propagating updates through embeddings rather than retraining entire models. The **Graphiti framework** from Zep implements temporally-aware knowledge graphs that support incremental updates without complete graph recomputation—essential for real-time coding assistant scenarios.

Key techniques for avoiding knowledge drift include:

- **Version control integration**: Storing ontology schemas in Git alongside code
- **Entity linking**: Maintaining stable identifiers for code entities across refactoring
- **Temporal validity**: Timestamping facts and maintaining historical knowledge states
- **Conflict resolution**: Using recency and source reliability to prioritize conflicting information

---

## Hybrid architectures balance accuracy, latency, and explainability

Three primary architectural patterns have emerged for combining LLMs with knowledge graphs, each with distinct trade-offs relevant to coding assistants.

**GraphRAG** (Microsoft Research) represents the most mature approach for document-heavy scenarios. It builds hierarchical knowledge graphs by extracting entities and relationships with LLMs, clustering them using the Leiden algorithm, and generating community summaries. At query time, it performs map-reduce operations over these summaries for global reasoning, or fans out from specific entities for local queries. Benchmarks show **3.4× improvement** on schema-bound queries compared to vector RAG, with particular strength in answering holistic questions about entire codebases.

**GNN-RAG** combines graph neural networks for dense graph reasoning with LLMs for language generation. The GNN traverses knowledge graph subgraphs to extract answer candidates and reasoning paths, which are then verbalized for the LLM. This achieves **5-15% improvement** on multi-hop and multi-entity questions while using smaller language models (7B parameters) effectively.

**Neuro-symbolic approaches** integrate logical reasoning with neural generation. Systems like AllegroGraph combine RDF knowledge graphs with Prolog for symbolic reasoning, using LLM function calling to invoke reasoning modules. This enables ontological constraints to guide and validate LLM outputs, reducing hallucination for domain-specific queries.

| Architecture | Latency | Multi-hop Reasoning | Setup Complexity | Best Use Case |
|--------------|---------|---------------------|------------------|---------------|
| Vector RAG | ~120ms | Limited | Low | Simple semantic search |
| GraphRAG Local | +20-40% overhead | Good | High | Connected code entities |
| GraphRAG Global | Higher (map-reduce) | Excellent | High | Architectural questions |
| GNN-RAG | Variable | Excellent | Very High | Complex relationship queries |
| Neuro-symbolic | Higher | Excellent + verifiable | Highest | Auditable reasoning |

For coding assistants, a **hybrid strategy** proves most practical: use vector search for initial broad recall (finding relevant code chunks), graph traversal for relationship refinement (understanding how entities connect), and pre-computed community summaries for architectural questions. Query classification at the entry point routes requests to the appropriate retrieval strategy, minimizing unnecessary graph operations for simple lookups.

---

## Capturing extended context transforms coding assistants into learning systems

Beyond code structure, effective knowledge graphs must capture the rich context surrounding development: conversations with developers, design rationale, test outcomes, runtime behavior, and links to external documentation.

The **Design Intent Ontology (DIO)** provides a formal framework for representing why decisions were made. Its core classes—DesignIntent, DesignIssue, Solution, Justification, Argument, Evidence—model the deliberation process developers engage in. Crucially, DIO links to W3C PROV-O, enabling provenance tracking that connects decisions to actors and timestamps. For an LLM-powered assistant, this means conversations can be transformed into structured design rationale:

```turtle
ex:RefactorDecision a dio:DesignDecision ;
    dio:governsDesign ex:NewArchitecture ;
    prov:wasAttributedTo ex:DeveloperAgent ;
    dio:hasMandatedSolution ex:MicroservicesSolution ;
    dio:hasJustification ex:ScalabilityJustification .
```

**LangChain's ConversationKGMemory** demonstrates practical conversation-to-knowledge-graph extraction, automatically identifying entities and relationships from dialogue to generate triples like `(Sam, favorite_color, red)`. The Graphiti framework extends this with temporal awareness, maintaining historical context while handling changing relationships—essential when a developer's understanding or requirements evolve.

For **test-code relationships**, graph coverage models where Control Flow Graph nodes represent statements and edges represent branches integrate naturally with knowledge graphs. Test failures can be semantically linked to specific code entities, enabling queries like "What tests cover function X?" or "Which code changes correlate with this test failure pattern?"

**Runtime behavior** captured through OpenTelemetry traces forms a directed acyclic graph of spans, each representing a unit of work with attributes, events, and parent relationships. Frameworks like SLOGERT transform raw logs into RDF knowledge graphs, enabling SPARQL queries over observability data. Linking spans to code entities creates powerful connections: "Show me the code paths that contribute to these slow database queries."

**External documentation linkage** closes the loop between project code and framework knowledge. GraphGen4Code demonstrates this at scale, linking library calls to 47 million forum posts. For Elixir projects, this means semantically connecting GenServer callbacks to OTP documentation, Phoenix controller actions to framework guides, and Ecto schemas to database pattern explanations.

---

## The Elixir ecosystem enables practical implementation

The Elixir/BEAM ecosystem provides surprisingly mature tooling for building LLM-augmented knowledge graph systems, centered on the **RDF.ex project**—a comprehensive suite of libraries for semantic web workloads.

| Library | Purpose | Maturity |
|---------|---------|----------|
| **RDF.ex** | Core RDF data structures, Turtle/N-Triples/JSON-LD serialization | Production-ready |
| **SPARQL.ex** | In-memory SPARQL query execution | Stable |
| **SPARQL.Client** | Query remote SPARQL 1.1 endpoints | Production-ready |
| **Grax** | Map RDF graphs to Elixir structs | Stable |
| **ShEx.ex** | RDF validation with Shape Expressions | Stable |

For graph database connectivity, **Bolt.Sips** provides mature Neo4j integration via the Bolt protocol, supporting transactions, connection pooling, and Cypher queries. For high-performance in-memory graph operations, **libgraph** offers pure Elixir graph algorithms including shortest path, connected components, and topological sorting.

Integration with the **Jido agent framework** follows naturally from its Skills and Actions architecture. Knowledge graph operations become Actions that can be composed:

```elixir
defmodule QueryKnowledgeGraph do
  use Jido.Action, name: "query_kg"
  
  def run(%{query: query, endpoint: endpoint}, _ctx) do
    case SPARQL.Client.query(query, endpoint) do
      {:ok, results} -> {:ok, %{results: results}}
      {:error, reason} -> {:error, reason}
    end
  end
end
```

A multi-agent architecture emerges naturally: **Retriever agents** specialize in graph traversal, **Update agents** handle knowledge ingestion, **Reasoning agents** orchestrate multi-step queries, and **Validator agents** verify facts against the knowledge graph. The BEAM's lightweight process model (approximately 25KB per agent) enables scaling to thousands of concurrent agents sharing a knowledge graph as persistent distributed memory.

For the storage layer, the recommended approach combines:

1. **Neo4j** via Bolt.Sips for the primary property graph store, leveraging its mature LangChain/LlamaIndex integrations
2. **Apache Jena Fuseki** via SPARQL.Client for RDF/OWL workloads requiring formal reasoning
3. **In-memory RDF.ex graphs** for working sets and local processing
4. **libgraph** for algorithm-heavy operations that benefit from native Elixir performance

---

## Real-world coding assistants increasingly adopt knowledge graph approaches

Existing coding assistants reveal a spectrum of knowledge approaches. **Cursor** explicitly builds "a knowledge graph of your entire codebase" for context-aware suggestions, indexing up to 50,000 files with project-wide understanding. **GitHub Copilot** relies on expanded context windows (64K-128K tokens) rather than explicit knowledge structures, though recent workspace agents add some structural awareness. **Augment Code** demonstrates enterprise scale with cross-repository indexing of 500,000 files.

Open-source projects provide implementation templates. **FalkorDB Code Graph** creates visual codebase explorers with LLM-to-Cypher query translation. **code-graph-rag** combines Tree-sitter parsing with Neo4j storage for monorepo RAG. The **Memento MCP** project (Claude/Cursor integration) implements Neo4j-backed knowledge graph memory via the Model Context Protocol.

Microsoft's GraphRAG offers the most comprehensive open-source implementation of LLM-driven knowledge graph construction, with community detection, hierarchical summarization, and multiple query modes. Its output can be imported into RDF triple stores for SPARQL-based reasoning, bridging the property graph and semantic web worlds.

---

## Conclusion: A practical path forward for Catena

Building an LLM-augmented knowledge graph for an Elixir coding assistant requires bridging theoretical ontology work with practical implementation. The key insight is that **code structure provides reliable ground truth through static analysis, while LLMs add semantic understanding that connects technical artifacts to human intent**.

For immediate implementation with Jido:

1. **Start with hybrid storage**: Use Neo4j for the primary code knowledge graph (leveraging Bolt.Sips), with RDF.ex for semantic linking and reasoning where OWL expressivity matters
2. **Implement AST-first extraction**: Parse Elixir code with existing tools, creating reliable structural entities before LLM semantic enrichment
3. **Design conversation-to-knowledge pipelines**: Transform developer interactions into DIO-compatible design rationale, building institutional memory
4. **Adopt GraphRAG patterns**: Community detection and hierarchical summarization enable answering architectural questions across entire codebases
5. **Link to framework documentation**: Connect project code to OTP, Phoenix, and Ecto documentation through semantic relationships

The category-theory grounding of Catena creates interesting possibilities: morphisms between code entities could be represented as first-class relationships in the knowledge graph, and categorical structures like functors and natural transformations might provide principled ways to model the relationships between runtime behavior and static code representations.

The BEAM's actor model aligns naturally with multi-agent knowledge graph architectures, where specialized agents collaborate through message passing while sharing a unified knowledge substrate. This isn't just an implementation convenience—it reflects how software understanding actually works: multiple perspectives (testing, operations, architecture, history) contributing to a coherent whole.
