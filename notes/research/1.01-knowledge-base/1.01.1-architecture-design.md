**Knowledge-Graph Memory for LLM Coding Assistants**

A knowledge graph (KG) can serve as a **persistent, structured memory** for an LLM-powered coding assistant, overcoming the LLM's limited context window and statelessness[arxiv.org](https://arxiv.org/html/2510.20345v1#:~:text=Achieving%20autonomy%20in%20LLM,term)[skywork.ai](https://skywork.ai/skypage/en/ai-agent-knowledge-graph/1980088995707211776#:~:text=limitation%20of%20many%20AI%20tools,C%20for). Instead of relying solely on transient prompts or vector-retrieval of documents, a KG records project knowledge (code elements, design decisions, bugs, user preferences, etc.) as interlinked triples. Graph databases (Neo4j, Memgraph, RDF triple stores) explicitly capture relationships (calls, inheritance, dependencies) and entity attributes, mirroring the project's architecture. Ontologies (RDFS/OWL) impose a formal schema: for example, defining classes like _Module_, _Function_, _Developer_ and relationships like _calls_, _implements_, _authored_by_. These enable logical inference (e.g. transitive "calls" chains, class hierarchies) that raw text or embeddings alone cannot[cognee.ai](https://www.cognee.ai/blog/deep-dives/ontology-ai-memory#:~:text=Ontology%20is%20essentially%20a%20formal,basic%20graph%20structures%2C%20ontologies%20provide)[semantic-web-journal.net](https://www.semantic-web-journal.net/system/files/swj2575.pdf#:~:text=to%20capture%20the%20semantics%20of,over%202%2C300%20Python%20modules%2C%20as). In practice, graph-augmented systems have shown dramatic gains: e.g. the "Knowledge Graph of Thoughts" approach uses a dynamic KG of task-related facts so that smaller LLMs achieve higher accuracy at lower cost[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2504.02670v6#:~:text=address%20these%20issues%2C%20we%20propose,4o). In summary, a KG provides rich, evolving context for the assistant - effectively a **"code-aware brain"** that grows with the project[skywork.ai](https://skywork.ai/skypage/en/ai-agent-knowledge-graph/1980088995707211776#:~:text=limitation%20of%20many%20AI%20tools,C%20for)[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can).

**Related Approaches and Tools**

Recent research has explored similar ideas. The _Zep/Graphiti_ system maintains a **temporal KG memory**: it ingests every interaction (commits, chats, docs) as an "episode", uses LLM tools to extract entities/relations, and updates a KG with validity intervals[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2501.13956v1#:~:text=In%20Zep%2C%20memory%20is%20powered,subgraph%2C%20and%20a%20community%20subgraph)[arxiv.org](https://arxiv.org/html/2510.20345v1#:~:text=Achieving%20autonomy%20in%20LLM,term). Zep's KG has hierarchical tiers (episodes, semantic entities, and "community" clusters of related entities) to mimic human episodic and semantic memory[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2501.13956v1#:~:text=In%20Zep%2C%20memory%20is%20powered,subgraph%2C%20and%20a%20community%20subgraph). Other frameworks (e.g. _Cognee_) combine RDF+OWL ontologies with LLMs to ensure consistency and infer new facts[cognee.ai](https://www.cognee.ai/blog/deep-dives/ontology-ai-memory#:~:text=Ontology%20is%20essentially%20a%20formal,basic%20graph%20structures%2C%20ontologies%20provide). **GraphRAG** techniques (e.g. Memgraph's Graph-Code) parse an entire codebase into a graph of files, modules, classes and call relationships[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can). In Graph-Code, the LLM translates user queries into graph queries (Cypher) over this code graph[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=The%20workflow%20is%20straightforward%20yet,maximum%20function%20call%20chain%20length). This gives the assistant a "bird's eye view" of the repository that pure RAG tools lack[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can). For example, the figure below shows a project node (center) linked to many functions and modules - Graph-Code lets the agent run queries on this structure to answer global questions (like "what depends on module X?")[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can)[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=The%20workflow%20is%20straightforward%20yet,maximum%20function%20call%20chain%20length).

_Figure: Example codebase knowledge graph (from Memgraph's Graph-Code demo). Nodes represent project/module/function entities and edges represent relationships (calls, contains, etc.). An LLM can query this graph (via generated Cypher) to answer high-level questions_[_memgraph.com_](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can)[_memgraph.com_](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=The%20workflow%20is%20straightforward%20yet,maximum%20function%20call%20chain%20length)_._

Furthermore, large-scale efforts like **Graph4Code** (IBM) demonstrate building an RDF KG of code and documentation at scale. Graph4Code parsed millions of Python files and StackOverflow posts into an RDF graph (using the SIO ontology) where classes, functions and data-flow edges are explicit[semantic-web-journal.net](https://www.semantic-web-journal.net/system/files/swj2575.pdf#:~:text=to%20capture%20the%20semantics%20of,over%202%2C300%20Python%20modules%2C%20as)[semantic-web-journal.net](https://www.semantic-web-journal.net/system/files/swj2575.pdf#:~:text=2,and%20Schema.org%20classes%20and). This makes semantic code search and refactoring possible. The lesson: an LLM coding assistant can leverage similar code-centric ontologies to enrich its KG. In summary, whether from academic or industry projects, the pattern is clear: _extract structured code knowledge into a graph, use LLMs to query and update that graph over time_[semantic-web-journal.net](https://www.semantic-web-journal.net/system/files/swj2575.pdf#:~:text=to%20capture%20the%20semantics%20of,over%202%2C300%20Python%20modules%2C%20as)[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can).

**Designing the Project Ontology**

The first step is defining **what to store** in the KG. One would create an ontology of project concepts: e.g. classes for _Project_, _Module/File_, _Class_, _Function/Method_, _Variable_, _Interface_, _Issue_, _Commit_, _Developer_, _Service_, _API_, etc. Relationships could include **"contains"** (module contains class/function), **"calls/uses"** (function A calls function B), **"implements"** (class implements interface), **"inherits"** (class hierarchy), **"defined_in"**, **"modified_by"** (commit or dev), **"related_to"** (bug reports, tickets), etc. Properties on nodes (data values) might include docstrings, types, parameters, code metrics, or semantic summaries. For example, Graph4Code used SIO/Schema.org terms and RDF labels to link code elements to documentation[semantic-web-journal.net](https://www.semantic-web-journal.net/system/files/swj2575.pdf#:~:text=2,and%20Schema.org%20classes%20and). An ontology formalizes this so the KG can infer new facts (e.g. if A→B and B→C, infer A→C) and check consistency[cognee.ai](https://www.cognee.ai/blog/deep-dives/ontology-ai-memory#:~:text=Ontology%20is%20essentially%20a%20formal,basic%20graph%20structures%2C%20ontologies%20provide).

The Elixir **RDF.ex** library supports RDFS/OWL modeling: one can define your classes and predicates and use RDF.Turtle or JSON-LD to instantiate data. (Tony Hammond's Elixir example uses the rdf package and SPARQL client for querying[medium.com](https://medium.com/@tonyhammond/graph-to-graph-with-elixir-9cd7fd6f2128#:~:text=And%20for%20accessing%20an%20RDF,memory%20RDF%20models).) In practice, the ontology might start simple (e.g. _Function rdfs:subClassOf CodeEntity_) and be extended as the project grows. The LLM itself can help refine the schema: by annotating new entity types or relationships in text, which an agent then formalizes into RDFS axioms[cognee.ai](https://www.cognee.ai/blog/deep-dives/ontology-ai-memory#:~:text=Ontology%20is%20essentially%20a%20formal,basic%20graph%20structures%2C%20ontologies%20provide)[arxiv.org](https://arxiv.org/html/2510.20345v1#:~:text=Achieving%20autonomy%20in%20LLM,term).

**System Architecture and Workflow**

The overall system operates in a loop of **perception, storage, retrieval, and reasoning**. A possible architecture is: Sensors monitor project events (git commits, code edits, documentation changes, chat with the developer). Each event is packaged as an "episode" and sent through an **extraction pipeline** (often LLM-based) that identifies entities and relationships. These triples are stored in the persistent KG (an RDF store or graph DB). When the developer asks a question or the agent needs context, a **retrieval component** queries the KG (via SPARQL or graph queries) to fetch relevant facts. These facts are combined into the LLM's prompt (Graph RAG) or used in an external graph query step. Finally, the LLM's response may **update the KG**: for example, the assistant might write a summary node, annotate code elements, or link issues, closing the loop[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2501.13956v1#:~:text=In%20Zep%2C%20memory%20is%20powered,subgraph%2C%20and%20a%20community%20subgraph)[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2504.02670v6#:~:text=address%20these%20issues%2C%20we%20propose,4o).

_Figure: Example architecture flow (inspired by Zep/Graphiti). Raw inputs (code commits, chats, docs) are processed into a dynamic knowledge graph. Relevant subgraphs are retrieved and assembled as context for the LLM, whose output may in turn generate new graph updates_[_getzep.com_](https://www.getzep.com/#:~:text=1)[_getzep.com_](https://www.getzep.com/#:~:text=Relevant%20Retrieval)_._

Key components include:

- **KG Store** - an RDF graph persisted locally (e.g. a file or embedded DB). This holds all triples about the project. In Elixir one could use RDF.Graph and dump to Turtle, or integrate with Neo4j via Bolt+neosemantics[medium.com](https://medium.com/@tonyhammond/graph-to-graph-with-elixir-9cd7fd6f2128#:~:text=And%20for%20accessing%20an%20RDF,memory%20RDF%20models).
- **Episode Ingestion** - each significant action (code push, PR merge, chat message) becomes an episode. Graphiti's design, for instance, keeps raw episodes as nodes linked to extracted entity nodes[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2501.13956v1#:~:text=In%20Zep%2C%20memory%20is%20powered,subgraph%2C%20and%20a%20community%20subgraph). This non-lossy storage means we never discard history.
- **Entity Extraction** - triggered by episodes, this step uses an LLM or rules to parse content into triples. For code, this could combine AST analysis (like Graph4Code) and NLP (doc strings, comments) to recognize functions, classes, parameters, etc. Each entity is resolved against the KG (to avoid duplicates) or added as a new node.
- **Ontology Enforcement** - an engine (or the LLM) checks new triples against the ontology, inferring any additional edges (e.g. subclass relations) and validating constraints[cognee.ai](https://www.cognee.ai/blog/deep-dives/ontology-ai-memory#:~:text=Ontology%20is%20essentially%20a%20formal,basic%20graph%20structures%2C%20ontologies%20provide)[semantic-web-journal.net](https://www.semantic-web-journal.net/system/files/swj2575.pdf#:~:text=2,and%20Schema.org%20classes%20and).
- **Query/Reasoning** - when context is needed, the agent queries the KG. This might be as simple as a keyword entity search, or more advanced: translating an English question into SPARQL/Cypher (as Graph-Code does)[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=The%20workflow%20is%20straightforward%20yet,maximum%20function%20call%20chain%20length). The returned subgraph is summarized (via template or LLM) into text context.
- **Context Assembly** - the retrieved facts (entities + relationships) are formatted into the LLM prompt, along with any relevant raw text (code snippets, docs). As Zep describes, the system "dynamically integrates user preferences, conversation history, and business data" from the KG into a single context block[getzep.com](https://www.getzep.com/#:~:text=1)[getzep.com](https://www.getzep.com/#:~:text=Relevant%20Retrieval).
- **LLM Integration** - Jido agents (using the jido_ai extension) can manage these steps. For example, a Jido workflow might: watch for a commit event, call a Python action to parse code, then call an Anthropic/OpenAI action to extract semantics. Jido's **Actions/Workflows/Sensors** primitives are ideal: sensors detect file changes, actions run LLM calls, workflows define the sequence, and agents hold state[elixirforum.com](https://elixirforum.com/t/jido-a-sdk-for-building-autonomous-agent-systems/68418#:~:text=Jido%E2%80%99s%20architecture%20is%20built%20around,key%20patterns%20in%20autonomous%20systems)[elixirforum.com](https://elixirforum.com/t/jido-a-sdk-for-building-autonomous-agent-systems/68418#:~:text=Jido%20is%20designed%20as%20an,Jido%20via%20a%20custom%20Action).

This architecture is effectively a **closed loop**: each coding session enriches the KG, so the assistant "remembers" past sessions. Over time, the LLM becomes better informed about the project. In one scenario, early code exploration might populate the graph with modules and APIs; later, the assistant can immediately recall that knowledge (e.g. "We already discussed module X's purpose last week").

**Implementation in Elixir**

In Elixir, you'd leverage existing libraries and standards. The RDF.ex library provides data structures and serialization for RDF graphs, Turtle, SPARQL, etc. For graph databases, one could use bolt_sips (Neo4j driver) plus the neosemantics plugin to import/export RDF[medium.com](https://medium.com/@tonyhammond/graph-to-graph-with-elixir-9cd7fd6f2128#:~:text=And%20for%20accessing%20an%20RDF,memory%20RDF%20models). Jido serves as the **agent framework**: you would define Actions for "call LLM" (via jido_ai), "run code parser", and "update KG". The Jido forum discussion highlights that actions carry schemas and metadata, enabling dynamic reasoning at runtime[elixirforum.com](https://elixirforum.com/t/jido-a-sdk-for-building-autonomous-agent-systems/68418#:~:text=Jido%E2%80%99s%20architecture%20is%20built%20around,key%20patterns%20in%20autonomous%20systems). An Agent can maintain a reference to the project KG in its state, or use a separate process.

The Model Context Protocol (MCP) could further integrate tools: e.g. you could run a local "KG server" (like Diego Sasco's KGsMCP) that exposes the KG via JSON-RPC[skywork.ai](https://skywork.ai/skypage/en/ai-agent-knowledge-graph/1980088995707211776#:~:text=is%20an%20open%20standard%20for,The%20MCP). Then the LLM (if MCP-aware) can query the KG directly as an external tool. In practice, though, even without MCP, Jido can orchestrate LLM prompts and KG queries internally. Data flow might use SPARQL queries (via sparql_client) to retrieve triples; updates might be batched or transactionally applied with proper locking.

Scalability and performance considerations: Use indexes on entity labels, and consider a **temporal graph** (tag triples with timestamps) so you can query only recent facts. As Zep's evaluation shows, temporal KGs drastically improve cross-session recall[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2501.13956v1#:~:text=limitation%20through%20its%20core%20component,These%20results%20are)[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2501.13956v1#:~:text=The%20Graphiti%20KG%20engine%20dynamically,represent%20a%20complex%2C%20evolving%20world). Caching hot subgraphs and using efficient in-memory stores (e.g. Memgraph) can keep retrieval fast, as Graph-Code's in-memory approach demonstrates[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=Graph,friendly%20stack%2C%20which%20includes).

**Key Benefits and Challenges**

By combining an ontology-driven KG with an LLM, the assistant gains:

- **Persistent Project Context:** The KG "remembers" code structure, conventions, past decisions and so on, so the LLM needn't re-learn basics each session[skywork.ai](https://skywork.ai/skypage/en/ai-agent-knowledge-graph/1980088995707211776#:~:text=limitation%20of%20many%20AI%20tools,C%20for)[arxiv.org](https://arxiv.org/html/2510.20345v1#:~:text=Achieving%20autonomy%20in%20LLM,term).
- **Structured Retrieval:** Graph queries yield precise context (multi-hop relations, deductive inference) that pure vector search may miss[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can)[cognee.ai](https://www.cognee.ai/blog/deep-dives/ontology-ai-memory#:~:text=Ontology%20is%20essentially%20a%20formal,basic%20graph%20structures%2C%20ontologies%20provide).
- **Explainability:** A KG makes the assistant's knowledge inspectable (you can query _why_ an answer was given by tracing graph edges)[arxiv.org](https://arxiv.org/html/2510.20345v1#:~:text=6,in%20LLM%20Applications%3A%20Beyond%20RAG).
- **Self-Improvement:** The LLM can write back to the KG (e.g. labeling code, flagging issues) so the memory improves continuously (similar to how KGoT refines its KG over task execution[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2504.02670v6#:~:text=address%20these%20issues%2C%20we%20propose,4o)).

Challenges include designing the right ontology (avoiding over-complex schemas), managing noise (filtering hallucinated facts), and merging overlapping data (entity resolution). Existing tools like Graphiti handle consistency checking, and frameworks like Cognee explore grounding LLM facts with formal rules[cognee.ai](https://www.cognee.ai/blog/deep-dives/ontology-ai-memory#:~:text=Ontology%20is%20essentially%20a%20formal,basic%20graph%20structures%2C%20ontologies%20provide). With careful design, however, this agentic KG approach promises a much smarter coding assistant - one that truly "understands" your project over time rather than starting each query from scratch[skywork.ai](https://skywork.ai/skypage/en/ai-agent-knowledge-graph/1980088995707211776#:~:text=limitation%20of%20many%20AI%20tools,C%20for)[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can).

**Sources:** Research on LLM memory graphs and ontologies[arxiv.org](https://arxiv.org/html/2510.20345v1#:~:text=Achieving%20autonomy%20in%20LLM,term)[ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2504.02670v6#:~:text=address%20these%20issues%2C%20we%20propose,4o)[getzep.com](https://www.getzep.com/#:~:text=1)[cognee.ai](https://www.cognee.ai/blog/deep-dives/ontology-ai-memory#:~:text=Ontology%20is%20essentially%20a%20formal,basic%20graph%20structures%2C%20ontologies%20provide)[memgraph.com](https://memgraph.com/blog/graphrag-for-devs-coding-assistant#:~:text=By%20treating%20the%20codebase%20as,a%20graph%2C%20you%20can)[skywork.ai](https://skywork.ai/skypage/en/ai-agent-knowledge-graph/1980088995707211776#:~:text=is%20an%20open%20standard%20for,The%20MCP)[semantic-web-journal.net](https://www.semantic-web-journal.net/system/files/swj2575.pdf#:~:text=to%20capture%20the%20semantics%20of,over%202%2C300%20Python%20modules%2C%20as)[semantic-web-journal.net](https://www.semantic-web-journal.net/system/files/swj2575.pdf#:~:text=2,and%20Schema.org%20classes%20and)[elixirforum.com](https://elixirforum.com/t/jido-a-sdk-for-building-autonomous-agent-systems/68418#:~:text=Jido%E2%80%99s%20architecture%20is%20built%20around,key%20patterns%20in%20autonomous%20systems)[medium.com](https://medium.com/@tonyhammond/graph-to-graph-with-elixir-9cd7fd6f2128#:~:text=And%20for%20accessing%20an%20RDF,memory%20RDF%20models) provides the foundation for these design principles. Each cited work illustrates aspects of the proposed architecture, from dynamic knowledge graphs (Zep, Graphiti) to code-specific KGs (Graph4Code, Graph-Code).
